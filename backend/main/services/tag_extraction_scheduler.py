"""
å¯¹è¯æ ‡ç­¾æå–è°ƒåº¦æœåŠ¡ - ã€æ ¸å¿ƒæ–‡ä»¶ã€‘
~~~~~~~~~~~~~~~

å®šæ—¶å¤„ç†ç”¨æˆ·å¯¹è¯ï¼Œè‡ªåŠ¨æå–æ ‡ç­¾å¹¶æ›´æ–°ç”¨æˆ·ç”»åƒ

åŠŸèƒ½ï¼š
- å®šæ—¶æ‰«æç”¨æˆ·å¯¹è¯ï¼ˆé»˜è®¤5åˆ†é’Ÿé—´éš”ï¼‰
- æ™ºèƒ½ç­›é€‰å¾…å¤„ç†çš„å¯¹è¯ï¼ˆæœ€è¿‘24å°æ—¶ï¼Œè‡³å°‘3æ¡æ¶ˆæ¯ï¼‰
- ä½¿ç”¨DeepSeek AIæå–ç”¨æˆ·æ ‡ç­¾
- è‡ªåŠ¨æ›´æ–°ç”¨æˆ·æ ‡ç­¾æ•°æ®åº“
- åŒæ­¥æ ‡ç­¾åˆ°Cozeå¹³å°
- é˜²é‡å¤å¤„ç†æœºåˆ¶ï¼ˆ60åˆ†é’Ÿå†…å·²å¤„ç†çš„è·³è¿‡ï¼‰

æ ¸å¿ƒç»„ä»¶ï¼š
- TagExtractionScheduler: ä¸»è°ƒåº¦æœåŠ¡ç±»
- _process_tag_extractions(): æ ‡ç­¾æå–å¤„ç†é€»è¾‘
- _process_conversation_tags(): å•å¯¹è¯æ ‡ç­¾æå–
- _get_pending_conversations(): æ™ºèƒ½å¯¹è¯ç­›é€‰

ä½¿ç”¨æ–¹å¼ï¼š
- APIæ§åˆ¶: /api/tag-scheduler/start|stop|status
- ç‹¬ç«‹è„šæœ¬: scripts/tag_extraction_worker.py
- åå°è¿è¡Œ: ./scripts/start_tag_scheduler.sh

ä½œè€…: æ™ºç³–å›¢é˜Ÿ
æ—¥æœŸ: 2025-01-21
"""

import time
import threading
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from utils.logger import get_logger
from utils.database import execute_query, execute_update
from services.tag_service import get_tag_service
from services.deepseek_service import get_deepseek_service

logger = get_logger(__name__)


class TagExtractionScheduler:
    """
    å¯¹è¯æ ‡ç­¾æå–è°ƒåº¦æœåŠ¡

    å®šæœŸå¤„ç†ç”¨æˆ·å¯¹è¯ï¼Œè‡ªåŠ¨æå–æ ‡ç­¾ä¿¡æ¯
    """

    def __init__(self, check_interval: int = 300):
        """
        åˆå§‹åŒ–è°ƒåº¦æœåŠ¡

        Args:
            check_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤5åˆ†é’Ÿ
        """
        self.check_interval = check_interval
        self.is_running = False
        self.thread = None

        # è·å–ä¾èµ–æœåŠ¡
        self.tag_service = get_tag_service()
        self.deepseek_service = get_deepseek_service()

        logger.info("âœ… æ ‡ç­¾æå–è°ƒåº¦æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    def start(self):
        """å¯åŠ¨è°ƒåº¦æœåŠ¡"""
        if self.is_running:
            logger.warning("âš ï¸ æ ‡ç­¾æå–è°ƒåº¦æœåŠ¡å·²åœ¨è¿è¡Œä¸­")
            return

        self.is_running = True
        self.thread = threading.Thread(target=self._run_scheduler, daemon=True)
        self.thread.start()

        logger.info(f"ğŸš€ æ ‡ç­¾æå–è°ƒåº¦æœåŠ¡å·²å¯åŠ¨ï¼Œæ£€æŸ¥é—´éš”: {self.check_interval}ç§’")

    def stop(self):
        """åœæ­¢è°ƒåº¦æœåŠ¡"""
        if not self.is_running:
            logger.warning("âš ï¸ æ ‡ç­¾æå–è°ƒåº¦æœåŠ¡æœªè¿è¡Œ")
            return

        self.is_running = False
        if self.thread:
            self.thread.join(timeout=10)

        logger.info("ğŸ›‘ æ ‡ç­¾æå–è°ƒåº¦æœåŠ¡å·²åœæ­¢")

    def _run_scheduler(self):
        """è¿è¡Œè°ƒåº¦å¾ªç¯"""
        logger.info("ğŸ”„ å¼€å§‹æ ‡ç­¾æå–è°ƒåº¦å¾ªç¯")

        while self.is_running:
            try:
                # æ‰§è¡Œæ ‡ç­¾æå–ä»»åŠ¡
                self._process_tag_extractions()

                # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                time.sleep(self.check_interval)

            except Exception as e:
                logger.error(f"âŒ æ ‡ç­¾æå–è°ƒåº¦å¾ªç¯é”™è¯¯: {str(e)}")
                time.sleep(60)  # å‡ºé”™åç­‰å¾…1åˆ†é’Ÿå†è¯•

    def _process_tag_extractions(self):
        """å¤„ç†æ ‡ç­¾æå–ä»»åŠ¡"""
        try:
            logger.info("ğŸ” å¼€å§‹æ£€æŸ¥éœ€è¦å¤„ç†çš„å¯¹è¯...")

            # è·å–éœ€è¦å¤„ç†çš„å¯¹è¯
            conversations = self._get_pending_conversations()

            if not conversations:
                logger.info("ğŸ“­ æš‚æ— éœ€è¦å¤„ç†çš„å¯¹è¯")
                return

            logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(conversations)} ä¸ªå¯¹è¯éœ€è¦å¤„ç†æ ‡ç­¾")

            processed_count = 0
            tag_count = 0

            for conversation in conversations:
                try:
                    # å¤„ç†å•ä¸ªå¯¹è¯
                    result = self._process_conversation_tags(conversation)

                    if result['success']:
                        processed_count += 1
                        tag_count += result.get('tag_count', 0)

                        logger.info(f"âœ… å¤„ç†å¯¹è¯ {conversation['conversation_id']}: æå–äº† {result.get('tag_count', 0)} ä¸ªæ ‡ç­¾")

                    else:
                        logger.warning(f"âš ï¸ å¤„ç†å¯¹è¯ {conversation['conversation_id']} å¤±è´¥: {result.get('message')}")

                except Exception as e:
                    logger.error(f"âŒ å¤„ç†å¯¹è¯ {conversation['conversation_id']} æ—¶å‡ºé”™: {str(e)}")

            logger.info(f"ğŸ“Š æœ¬æ¬¡å¤„ç†å®Œæˆ: {processed_count}/{len(conversations)} ä¸ªå¯¹è¯æˆåŠŸï¼Œæå–äº† {tag_count} ä¸ªæ ‡ç­¾")

        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ ‡ç­¾æå–ä»»åŠ¡å¤±è´¥: {str(e)}")

    def _get_pending_conversations(self, hours_back: int = 24) -> List[Dict[str, Any]]:
        """
        è·å–éœ€è¦å¤„ç†çš„å¯¹è¯

        Args:
            hours_back: æ£€æŸ¥æœ€è¿‘å¤šå°‘å°æ—¶çš„å¯¹è¯ï¼Œé»˜è®¤24å°æ—¶

        Returns:
            List[Dict]: å¾…å¤„ç†çš„å¯¹è¯åˆ—è¡¨
        """
        try:
            # è®¡ç®—æ—¶é—´èŒƒå›´
            time_threshold = datetime.now() - timedelta(hours=hours_back)

            # æŸ¥è¯¢æœ€è¿‘çš„å¯¹è¯ï¼ŒæŒ‰ç”¨æˆ·åˆ†ç»„è·å–æœ€æ–°çš„å¯¹è¯
            sql = """
                SELECT
                    cm.user_id,
                    cm.conversation_id,
                    MAX(cm.created_at) as last_message_time,
                    COUNT(*) as message_count,
                    GROUP_CONCAT(cm.content ORDER BY cm.created_at SEPARATOR '\\n') as conversation_content
                FROM chat_messages cm
                WHERE cm.created_at >= %s
                  AND cm.role = 'user'
                  AND LENGTH(cm.content) > 10  -- åªå¤„ç†æœ‰æ„ä¹‰çš„å¯¹è¯
                GROUP BY cm.user_id, cm.conversation_id
                HAVING message_count >= 3  -- è‡³å°‘æœ‰3æ¡æ¶ˆæ¯çš„å¯¹è¯
                ORDER BY last_message_time DESC
                LIMIT 50  -- æ¯æ¬¡æœ€å¤šå¤„ç†50ä¸ªå¯¹è¯
            """

            conversations = execute_query(sql, (time_threshold,))

            # è¿‡æ»¤æ‰æœ€è¿‘å·²ç»å¤„ç†è¿‡çš„å¯¹è¯
            filtered_conversations = []
            for conv in conversations:
                if not self._is_conversation_processed_recently(conv['conversation_id']):
                    # æˆªå–å¯¹è¯å†…å®¹ï¼ˆæœ€è¿‘çš„1000ä¸ªå­—ç¬¦ï¼‰
                    conv['conversation_content'] = conv['conversation_content'][-1000:]
                    filtered_conversations.append(conv)

            return filtered_conversations

        except Exception as e:
            logger.error(f"âŒ è·å–å¾…å¤„ç†å¯¹è¯å¤±è´¥: {str(e)}")
            return []

    def _is_conversation_processed_recently(self, conversation_id: str, minutes_back: int = 60) -> bool:
        """
        æ£€æŸ¥å¯¹è¯æ˜¯å¦åœ¨æœ€è¿‘ä¸€æ®µæ—¶é—´å†…å·²ç»å¤„ç†è¿‡

        Args:
            conversation_id: å¯¹è¯ID
            minutes_back: æ£€æŸ¥æœ€è¿‘å¤šå°‘åˆ†é’Ÿï¼Œé»˜è®¤60åˆ†é’Ÿ

        Returns:
            bool: æ˜¯å¦æœ€è¿‘å¤„ç†è¿‡
        """
        try:
            time_threshold = datetime.now() - timedelta(minutes=minutes_back)

            sql = """
                SELECT COUNT(*) as count
                FROM user_tag_history
                WHERE conversation_id = %s
                  AND updated_at >= %s
                  AND source = 'ai_extract'
            """

            result = execute_query(sql, (conversation_id, time_threshold), fetch_one=True)
            return result['count'] > 0

        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥å¯¹è¯å¤„ç†çŠ¶æ€å¤±è´¥: {str(e)}")
            return False

    def _process_conversation_tags(self, conversation: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªå¯¹è¯çš„æ ‡ç­¾æå–

        Args:
            conversation: å¯¹è¯ä¿¡æ¯

        Returns:
            Dict: å¤„ç†ç»“æœ
        """
        try:
            user_id = conversation['user_id']
            conversation_id = conversation['conversation_id']
            content = conversation['conversation_content']

            logger.info(f"ğŸ¤– å¼€å§‹ä¸ºç”¨æˆ· {user_id} çš„å¯¹è¯ {conversation_id} æå–æ ‡ç­¾")

            # ä½¿ç”¨DeepSeek AIæå–æ ‡ç­¾
            extracted_tags = self.deepseek_service.tag_user_from_conversation(user_id, content)

            if not extracted_tags:
                return {
                    'success': True,
                    'tag_count': 0,
                    'message': 'æœªæå–åˆ°æ ‡ç­¾'
                }

            # æ‰¹é‡è®¾ç½®æ ‡ç­¾
            tag_results = []
            for tag_info in extracted_tags:
                try:
                    result = self.tag_service.set_user_tag(
                        user_id=user_id,
                        tag_key=tag_info.get('tag_key', ''),
                        tag_value=tag_info.get('tag_value', ''),
                        source='ai_extract',
                        conversation_id=conversation_id,  # ä¼ é€’å¯¹è¯ID
                        auto_sync_coze=True
                    )

                    if result.get('success'):
                        tag_results.append({
                            'tag_key': tag_info.get('tag_key'),
                            'tag_value': tag_info.get('tag_value'),
                            'confidence': tag_info.get('confidence', 0.5)
                        })

                except Exception as e:
                    logger.warning(f"âš ï¸ è®¾ç½®æ ‡ç­¾ {tag_info.get('tag_key')} å¤±è´¥: {str(e)}")

            # åŒæ­¥æ ‡ç­¾åˆ°Coze
            try:
                sync_result = self.tag_service.sync_user_tags_to_coze(user_id)
                if sync_result:
                    logger.info(f"âœ… ç”¨æˆ· {user_id} çš„æ ‡ç­¾å·²åŒæ­¥åˆ°Coze")
                else:
                    logger.warning(f"âš ï¸ ç”¨æˆ· {user_id} çš„æ ‡ç­¾åŒæ­¥åˆ°Cozeå¤±è´¥")
            except Exception as e:
                logger.error(f"âŒ åŒæ­¥æ ‡ç­¾åˆ°Cozeå¤±è´¥: {str(e)}")

            return {
                'success': True,
                'tag_count': len(tag_results),
                'tags': tag_results
            }

        except Exception as e:
            logger.error(f"âŒ å¤„ç†å¯¹è¯æ ‡ç­¾æå–å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'message': str(e)
            }

    def process_single_conversation(self, user_id: int, conversation_id: str) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªå¯¹è¯çš„æ ‡ç­¾æå–ï¼ˆæ‰‹åŠ¨è°ƒç”¨ï¼‰

        Args:
            user_id: ç”¨æˆ·ID
            conversation_id: å¯¹è¯ID

        Returns:
            Dict: å¤„ç†ç»“æœ
        """
        try:
            # è·å–å¯¹è¯å†…å®¹
            sql = """
                SELECT
                    cm.user_id,
                    cm.conversation_id,
                    GROUP_CONCAT(cm.content ORDER BY cm.created_at SEPARATOR '\\n') as conversation_content
                FROM chat_messages cm
                WHERE cm.conversation_id = %s AND cm.user_id = %s
                GROUP BY cm.conversation_id
            """

            conversation = execute_query(sql, (conversation_id, user_id), fetch_one=True)

            if not conversation:
                return {
                    'success': False,
                    'message': 'å¯¹è¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®'
                }

            # å¤„ç†æ ‡ç­¾æå–
            return self._process_conversation_tags(conversation)

        except Exception as e:
            logger.error(f"âŒ å¤„ç†å•ä¸ªå¯¹è¯å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'message': str(e)
            }

    def get_scheduler_status(self) -> Dict[str, Any]:
        """
        è·å–è°ƒåº¦æœåŠ¡çŠ¶æ€

        Returns:
            Dict: æœåŠ¡çŠ¶æ€ä¿¡æ¯
        """
        return {
            'is_running': self.is_running,
            'check_interval': self.check_interval,
            'thread_alive': self.thread.is_alive() if self.thread else False,
            'next_check_in': self.check_interval if self.is_running else None
        }


# å…¨å±€å•ä¾‹å®ä¾‹
_scheduler_instance: Optional[TagExtractionScheduler] = None


def get_tag_extraction_scheduler() -> TagExtractionScheduler:
    """è·å–æ ‡ç­¾æå–è°ƒåº¦æœåŠ¡å•ä¾‹"""
    global _scheduler_instance
    if _scheduler_instance is None:
        _scheduler_instance = TagExtractionScheduler()
    return _scheduler_instance


def start_tag_extraction_scheduler():
    """å¯åŠ¨æ ‡ç­¾æå–è°ƒåº¦æœåŠ¡"""
    scheduler = get_tag_extraction_scheduler()
    scheduler.start()
    return scheduler


def stop_tag_extraction_scheduler():
    """åœæ­¢æ ‡ç­¾æå–è°ƒåº¦æœåŠ¡"""
    scheduler = get_tag_extraction_scheduler()
    scheduler.stop()
    return scheduler
