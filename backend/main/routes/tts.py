"""
TTSè·¯ç”±
~~~~~~

æ–‡æœ¬è½¬è¯­éŸ³çš„APIç«¯ç‚¹ï¼š
- æ–‡æœ¬è½¬è¯­éŸ³
- æ‰¹é‡è½¬è¯­éŸ³
- é¢„ç”Ÿæˆå¼•å¯¼è¯­éŸ³
- ç¼“å­˜ç®¡ç†

ä½œè€…: æ™ºç³–å›¢é˜Ÿ
æ—¥æœŸ: 2025-01-15
"""

from flask import request, jsonify, Response, stream_with_context
from . import tts_bp
from utils.jwt_helper import no_auth_required as token_required
from services.tts_service import get_tts_service
from utils.logger import get_logger
import json
import re
from typing import List

logger = get_logger(__name__)

# è·å–æœåŠ¡å®ä¾‹
tts_service = get_tts_service()


@tts_bp.route('/tts/stream', methods=['POST'], endpoint='stream_text_to_speech')
@token_required
def stream_text_to_speech(user_id):
    """
    æµå¼æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆåˆ†å¥å¤„ç†ï¼‰

    Headers:
        Authorization: Bearer <token>

    Body:
        {
            "text": "è¦è½¬æ¢çš„æ–‡æœ¬ï¼Œå¯ä»¥å¾ˆé•¿ã€‚ä¼šè‡ªåŠ¨æŒ‰å¥å­åˆ†å‰²ã€‚",
            "voice_id": "7426720361753903141",
            "speed": 1.0,
            "use_cache": true
        }

    Returns:
        SSEæµ: é€å¥è¿”å›éŸ³é¢‘æ•°æ®
    """
    try:
        data = request.get_json()

        text = data.get('text')
        if not text:
            return jsonify({
                'code': 400,
                'data': {},
                'success': False,
                'message': 'æ–‡æœ¬ä¸èƒ½ä¸ºç©º'
            }), 400

        voice_id = data.get('voice_id', '7426720361753903141')
        speed = float(data.get('speed', 1.0))
        use_cache = data.get('use_cache', True)
        
        def generate():
            try:
                logger.info(f"ğŸ¤ å¼€å§‹æµå¼TTSè½¬æ¢ï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}")
                
                # æŒ‰å¥å­åˆ†å‰²æ–‡æœ¬ï¼ˆæ”¹è¿›çš„åˆ†å‰²é€»è¾‘ï¼‰
                # é¦–å…ˆå°è¯•æŒ‰æ ‡å‡†å¥å­ç»“æŸç¬¦åˆ†å‰²
                sentences_list = []
                pattern = r'([ã€‚ï¼ï¼Ÿï¼›]+|[\n]{2,})'  # å¥å·ã€é—®å·ã€æ„Ÿå¹å·ã€åˆ†å·ï¼Œæˆ–è¿ç»­æ¢è¡Œ
                parts = re.split(pattern, text)
                
                # é‡æ–°ç»„åˆï¼šæ–‡æœ¬ç‰‡æ®µ + æ ‡ç‚¹ç¬¦å·
                current_sentence = ""
                for i, part in enumerate(parts):
                    part = part.strip() if part else ""
                    if not part:
                        continue
                    
                    # å¦‚æœæ˜¯æ ‡ç‚¹ç¬¦å·ï¼ˆå¥å·ã€é—®å·ã€æ„Ÿå¹å·ã€åˆ†å·ï¼‰æˆ–è¿ç»­æ¢è¡Œ
                    if re.match(r'^[ã€‚ï¼ï¼Ÿï¼›]+$', part) or re.match(r'^[\n]{2,}$', part):
                        current_sentence += part
                        if current_sentence.strip():
                            sentences_list.append(current_sentence.strip())
                            current_sentence = ""
                    else:
                        # æ˜¯æ–‡æœ¬å†…å®¹
                        current_sentence += part
                
                # æ·»åŠ æœ€åä¸€æ®µ
                if current_sentence.strip():
                    sentences_list.append(current_sentence.strip())

                # å¦‚æœæ²¡æœ‰åˆ†å‰²å‡ºå¥å­ï¼ˆæ²¡æœ‰æ ‡å‡†å¥å­ç»“æŸç¬¦ï¼‰ï¼Œå°è¯•æ›´æ™ºèƒ½çš„åˆ†å‰²
                if len(sentences_list) <= 1:
                    logger.info("ğŸ”„ æ²¡æœ‰æ‰¾åˆ°æ ‡å‡†å¥å­ç»“æŸç¬¦ï¼Œå°è¯•æ™ºèƒ½åˆ†å‰²...")

                    # æ–¹æ³•1ï¼šæŒ‰åˆ—è¡¨é¡¹åˆ†å‰²ï¼ˆ- å¼€å¤´çš„è¡Œï¼‰
                    if '\n- ' in text or text.startswith('- '):
                        logger.info("ğŸ“ æ£€æµ‹åˆ°åˆ—è¡¨æ ¼å¼ï¼ŒæŒ‰åˆ—è¡¨é¡¹åˆ†å‰²")
                        # æŒ‰åˆ—è¡¨é¡¹åˆ†å‰²
                        list_items = []
                        lines = text.split('\n')
                        current_item = ""

                        for line in lines:
                            line = line.strip()
                            if line.startswith('- ') or line.startswith('âœ… ') or line.startswith('âŒ ') or line.startswith('âš ï¸ ') or line.startswith('ğŸ‹ '):
                                # ä¿å­˜ä¹‹å‰çš„é¡¹
                                if current_item.strip():
                                    list_items.append(current_item.strip())
                                # å¼€å§‹æ–°é¡¹
                                current_item = line
                            elif line.strip():
                                # ç»§ç»­å½“å‰é¡¹
                                if current_item:
                                    current_item += '\n' + line
                                else:
                                    current_item = line

                        # æ·»åŠ æœ€åä¸€ä¸ªé¡¹
                        if current_item.strip():
                            list_items.append(current_item.strip())

                        if len(list_items) > 1:
                            sentences_list = list_items
                            logger.info(f"âœ… æŒ‰åˆ—è¡¨é¡¹åˆ†å‰²æˆåŠŸï¼Œå¾—åˆ° {len(sentences_list)} é¡¹")
                
                    # æ–¹æ³•2ï¼šæŒ‰æ®µè½åˆ†éš”ç¬¦ï¼ˆ**ï¼‰åˆ†å‰²
                    if len(sentences_list) <= 1 and '**' in text:
                        logger.info("ğŸ“ æ£€æµ‹åˆ°æ®µè½æ ¼å¼ï¼ŒæŒ‰**åˆ†å‰²")
                        # æŸ¥æ‰¾æ‰€æœ‰ **text** æ¨¡å¼
                        bold_pattern = r'\*\*.*?\*\*'
                        bold_parts = re.findall(bold_pattern, text)

                        if bold_parts:
                            para_sentences = []
                            remaining = text

                            for bold in bold_parts:
                                if bold in remaining:
                                    parts = remaining.split(bold, 1)
                                    if parts[0].strip():
                                        para_sentences.append(parts[0].strip())
                                    para_sentences.append(bold)
                                    remaining = parts[1] if len(parts) > 1 else ''

                            if remaining.strip():
                                para_sentences.append(remaining.strip())

                            # åˆå¹¶çŸ­å¥å­
                            merged = []
                            current = ""
                            for part in para_sentences:
                                if len(current + part) <= 300:  # ç¨å¾®æ”¾å®½é™åˆ¶
                                    current += (" " if current else "") + part
                                else:
                                    if current:
                                        merged.append(current)
                                    current = part
                            if current:
                                merged.append(current)

                            if len(merged) > 1:
                                sentences_list = merged
                                logger.info(f"âœ… æŒ‰æ®µè½åˆ†å‰²æˆåŠŸï¼Œå¾—åˆ° {len(sentences_list)} æ®µ")

                    # æ–¹æ³•3ï¼šæŒ‰å•ä¸ªæ¢è¡Œç¬¦åˆ†å‰²ï¼ˆæœ€åçš„fallbackï¼‰
                    if len(sentences_list) <= 1:
                        logger.info("ğŸ“ ä½¿ç”¨æ¢è¡Œç¬¦åˆ†å‰²ä½œä¸ºæœ€åæ‰‹æ®µ")
                        alt_sentences = [s.strip() for s in re.split(r'\n+', text) if s.strip()]
                        if len(alt_sentences) > len(sentences_list):
                            sentences_list = alt_sentences
                            logger.info(f"âœ… æŒ‰æ¢è¡Œç¬¦åˆ†å‰²æˆåŠŸï¼Œå¾—åˆ° {len(alt_sentences)} å¥")

                print(f"DEBUG: å¥å­åˆ†å‰²å®Œæˆï¼Œsentences_listé•¿åº¦: {len(sentences_list)}")
                # å¯¹è¿‡é•¿çš„å¥å­è¿›è¡Œå¼ºåˆ¶åˆ†å‰²
                print(f"DEBUG: å¼€å§‹å¼ºåˆ¶åˆ†å‰²ï¼Œsentences_listé•¿åº¦: {len(sentences_list)}")
                MAX_CHUNK_LENGTH = 200  # å•ä¸ªå¥å­æœ€å¤§é•¿åº¦
                processed_sentences = []
                logger.info(f"ğŸ” å¼€å§‹æ£€æŸ¥å¥å­é•¿åº¦ï¼Œå…± {len(sentences_list)} å¥ï¼Œæœ€å¤§é•¿åº¦é™åˆ¶: {MAX_CHUNK_LENGTH}")
                logger.info(f"ğŸ” sentences_listå†…å®¹: {[len(s) for s in sentences_list]}")
                print(f"DEBUG: MAX_CHUNK_LENGTH = {MAX_CHUNK_LENGTH}")

                for i, sent in enumerate(sentences_list):
                    logger.info(f"   å¥å­ {i+1} é•¿åº¦: {len(sent)} å­—ç¬¦, MAX_CHUNK_LENGTH: {MAX_CHUNK_LENGTH}")
                    if len(sent) <= MAX_CHUNK_LENGTH:
                        processed_sentences.append(sent)
                        logger.info(f"   å¥å­ {i+1} é•¿åº¦æ­£å¸¸ï¼Œä¿æŒä¸å˜")
                    else:
                        logger.info(f"   å¥å­ {i+1} è¶…è¿‡é•¿åº¦é™åˆ¶ï¼Œå¼€å§‹å¼ºåˆ¶åˆ†å‰²")
                        logger.warning(f"âš ï¸ å¥å­ {i+1} è¿‡é•¿ ({len(sent)} å­—ç¬¦)ï¼Œå¼ºåˆ¶åˆ†å‰²: {sent[:50]}...")
                        long_text = sent
                        sub_sentences = []

                        # æ–¹æ³•1ï¼šæŒ‰åˆ—è¡¨é¡¹åˆ†å‰²ï¼ˆ- å¼€å¤´çš„è¡Œï¼‰
                        has_list_markers = any(marker in long_text for marker in ['\n- ', '- ', '\nâœ… ', 'âœ… ', '\nâŒ ', 'âŒ ', '\nâš ï¸ ', 'âš ï¸ ', '\nğŸ‹ ', 'ğŸ‹ '])
                        logger.info(f"   æ£€æŸ¥åˆ—è¡¨æ ‡è®°: {has_list_markers}")

                        if has_list_markers:
                            logger.info("ğŸ”„ å¼ºåˆ¶æŒ‰åˆ—è¡¨é¡¹åˆ†å‰²é•¿å¥å­")
                            lines = long_text.split('\n')
                            current_item = ""

                            for line in lines:
                                line = line.strip()
                                if any(line.startswith(marker.strip()) for marker in ['- ', 'âœ… ', 'âŒ ', 'âš ï¸ ', 'ğŸ‹ ']):
                                    # ä¿å­˜ä¹‹å‰çš„é¡¹
                                    if current_item.strip():
                                        sub_sentences.append(current_item.strip())
                                    # å¼€å§‹æ–°é¡¹
                                    current_item = line
                                elif line.strip():
                                    # ç»§ç»­å½“å‰é¡¹
                                    if current_item:
                                        current_item += '\n' + line
                                    else:
                                        current_item = line

                            # æ·»åŠ æœ€åä¸€ä¸ªé¡¹
                            if current_item.strip():
                                sub_sentences.append(current_item.strip())

                            if len(sub_sentences) > 1:
                                logger.info(f"âœ… å¼ºåˆ¶æŒ‰åˆ—è¡¨é¡¹åˆ†å‰²æˆåŠŸï¼Œå¾—åˆ° {len(sub_sentences)} é¡¹")
                            else:
                                logger.warning(f"âŒ åˆ—è¡¨é¡¹åˆ†å‰²å¤±è´¥ï¼Œåªå¾—åˆ° {len(sub_sentences)} é¡¹")

                        # æ–¹æ³•2ï¼šæŒ‰æ¢è¡Œç¬¦åˆ†å‰²
                        if not sub_sentences:
                            lines = [line.strip() for line in long_text.split('\n') if line.strip()]
                            logger.info(f"   æŒ‰æ¢è¡Œç¬¦åˆ†å‰²æ£€æŸ¥: {len(lines)} è¡Œ")
                            if len(lines) > 1:
                                sub_sentences = lines
                                logger.info(f"âœ… å¼ºåˆ¶æŒ‰æ¢è¡Œç¬¦åˆ†å‰²æˆåŠŸï¼Œå¾—åˆ° {len(sub_sentences)} å¥")

                        # æ–¹æ³•3ï¼šæŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²
                        if not sub_sentences:
                            split_chars = ['ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›']
                            for char in split_chars:
                                if char in long_text:
                                    parts = long_text.split(char)
                                    candidates = []
                                    for j, part in enumerate(parts):
                                        part = part.strip()
                                        if part:
                                            if j < len(parts) - 1:  # ä¸æ˜¯æœ€åä¸€éƒ¨åˆ†
                                                candidates.append(part + char)
                                            else:  # æœ€åä¸€éƒ¨åˆ†
                                                candidates.append(part)

                                    if len(candidates) > 1:
                                        sub_sentences = candidates
                                        logger.info(f"âœ… å¼ºåˆ¶æŒ‰'{char}'åˆ†å‰²æˆåŠŸï¼Œå¾—åˆ° {len(sub_sentences)} å¥")
                                        break

                        # æ–¹æ³•4ï¼šç¡¬åˆ†å‰²
                        if not sub_sentences:
                            logger.warning("âš ï¸ æ‰€æœ‰åˆ†å‰²æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œä½¿ç”¨ç¡¬åˆ†å‰²")
                            chunk_size = 150  # ç¨å¾®å°ä¸€ç‚¹
                            start = 0
                            while start < len(long_text):
                                end = start + chunk_size
                                if end >= len(long_text):
                                    chunk = long_text[start:].strip()
                                    if chunk:
                                        sub_sentences.append(chunk)
                                    break

                                # å°½é‡åœ¨åˆé€‚ä½ç½®æ–­å¼€
                                best_end = end
                                for k in range(min(30, len(long_text) - start)):
                                    pos = end - k
                                    if pos > start and long_text[pos] in 'ã€‚ï¼ï¼Ÿï¼›\n ':
                                        best_end = pos + 1
                                        break

                                chunk = long_text[start:best_end].strip()
                                if chunk:
                                    sub_sentences.append(chunk)
                                start = best_end

                            logger.info(f"âœ… ç¡¬åˆ†å‰²å®Œæˆï¼Œå¾—åˆ° {len(sub_sentences)} å¥")

                        logger.info(f"   å¥å­ {i+1} è¢«åˆ†å‰²ä¸º {len(sub_sentences)} ä¸ªå­å¥")
                        processed_sentences.extend(sub_sentences)

                # ä¿®å¤ï¼šå°†processed_sentencesèµ‹å€¼ç»™sentences_list
                sentences_list = processed_sentences
                logger.info(f"ğŸ“Š æœ€ç»ˆå¥å­æ•°: {len(sentences_list)} å¥ï¼ˆåŒ…å«å¼ºåˆ¶åˆ†å‰²åçš„å­å¥ï¼‰")
                
                logger.info(f"ğŸ“Š æ–‡æœ¬åˆ†å‰²å®Œæˆï¼Œå…± {len(sentences_list)} å¥")
                # æ‰“å°æ‰€æœ‰å¥å­ç”¨äºè°ƒè¯•
                for idx, sent in enumerate(sentences_list, 1):
                    logger.info(f"   å¥å­ {idx}: {sent[:80]}{'...' if len(sent) > 80 else ''}")
                
                # å®šä¹‰å‡½æ•°ï¼šæ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«æœ‰æ•ˆçš„ä¸­æ–‡å­—ç¬¦æˆ–è‹±æ–‡å­—æ¯
                def has_valid_text(text: str) -> bool:
                    """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«æœ‰æ•ˆå­—ç¬¦ï¼ˆä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ï¼‰"""
                    if not text or not text.strip():
                        return False
                    # åŒ¹é…ä¸­æ–‡å­—ç¬¦ã€è‹±æ–‡å­—æ¯ã€æ•°å­—
                    pattern = r'[\u4e00-\u9fa5a-zA-Z0-9]'
                    return bool(re.search(pattern, text))

                # å®šä¹‰å‡½æ•°ï¼šæ™ºèƒ½æ‹†åˆ†é•¿å¥å­
                def split_long_sentence(text: str, max_length: int) -> List[str]:
                    """æ™ºèƒ½æ‹†åˆ†è¿‡é•¿çš„å¥å­ï¼Œé¿å…ç ´åè¯­ä¹‰"""
                    if len(text) <= max_length:
                        return [text]

                    logger.info(f"ğŸ“ å¼€å§‹æ‹†åˆ†é•¿å¥å­ ({len(text)} å­—ç¬¦)...")

                    # æ–¹æ³•1ï¼šæŒ‰markdownåˆ—è¡¨é¡¹ï¼ˆ- ï¼‰å’Œæ®µè½ï¼ˆ**ï¼‰ä¼˜å…ˆæ‹†åˆ†
                    if '\n- ' in text:
                        # æŒ‰åˆ—è¡¨é¡¹æ‹†åˆ†
                        parts = text.split('\n- ')
                        result = []
                        for i, part in enumerate(parts):
                            if i == 0:
                                result.append(part.strip())
                            else:
                                result.append(('- ' + part).strip())
                        # è¿‡æ»¤ç©ºå†…å®¹
                        result = [r for r in result if r.strip()]
                        if len(result) > 1:
                            logger.info(f"âœ… æŒ‰åˆ—è¡¨é¡¹æ‹†åˆ†ä¸º {len(result)} éƒ¨åˆ†")
                            return result

                    # æ–¹æ³•2ï¼šæŒ‰æ®µè½åˆ†éš”ç¬¦ï¼ˆ**ï¼‰æ‹†åˆ†
                    if '**' in text:
                        # æŸ¥æ‰¾æ‰€æœ‰ **text** æ¨¡å¼
                        bold_parts = re.findall(r'\*\*.*?\*\*', text)
                        if bold_parts:
                            result = []
                            remaining = text
                            for bold in bold_parts:
                                if bold in remaining:
                                    parts = remaining.split(bold, 1)
                                    if parts[0].strip():
                                        result.append(parts[0].strip())
                                    result.append(bold)
                                    remaining = parts[1] if len(parts) > 1 else ''
                            if remaining.strip():
                                result.append(remaining.strip())

                            # åˆå¹¶çŸ­å¥å­
                            merged = []
                            current = ""
                            for part in result:
                                if len(current + part) <= max_length:
                                    current += (" " if current else "") + part
                                else:
                                    if current:
                                        merged.append(current)
                                    current = part
                            if current:
                                merged.append(current)

                            if len(merged) > 1:
                                logger.info(f"âœ… æŒ‰æ®µè½æ‹†åˆ†ä¸º {len(merged)} éƒ¨åˆ†")
                                return merged

                    # æ–¹æ³•3ï¼šæŒ‰æ¢è¡Œç¬¦å’Œæ ‡ç‚¹ç¬¦å·æ‹†åˆ†
                    split_chars = ['\n\n', 'ã€‚\n', 'ï¼\n', 'ï¼Ÿ\n', 'ï¼›\n', '\n', 'ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›']
                    for char in split_chars:
                        if char in text:
                            parts = text.split(char)
                            result = []
                            current = ""
                            for part in parts:
                                candidate = current + (char if current else "") + part
                                if len(candidate) <= max_length:
                                    current = candidate
                                else:
                                    if current:
                                        result.append(current)
                                    current = part
                            if current:
                                result.append(current)

                            result = [r.strip() for r in result if r.strip()]
                            if len(result) > 1:
                                logger.info(f"âœ… æŒ‰'{char}'æ‹†åˆ†ä¸º {len(result)} éƒ¨åˆ†")
                                return result

                    # æ–¹æ³•4ï¼šæŒ‰é•¿åº¦ç¡¬æ‹†åˆ†ï¼ˆæœ€åæ‰‹æ®µï¼‰
                    logger.warning(f"âš ï¸ æ‰€æœ‰æ™ºèƒ½æ‹†åˆ†å¤±è´¥ï¼ŒæŒ‰é•¿åº¦ç¡¬æ‹†åˆ†: {len(text)} å­—ç¬¦")
                    result = []
                    start = 0
                    while start < len(text):
                        end = min(start + max_length, len(text))
                        # å°½é‡åœ¨æ ‡ç‚¹å¤„æ–­å¼€
                        if end < len(text):
                            for i in range(min(20, end - start)):
                                pos = end - i
                                if text[pos] in 'ã€‚ï¼ï¼Ÿï¼›.!?\n ':
                                    end = pos + 1
                                    break

                        chunk = text[start:end].strip()
                        if chunk:
                            result.append(chunk)
                        start = end

                    logger.info(f"âœ… ç¡¬æ‹†åˆ†ä¸º {len(result)} éƒ¨åˆ†")
                    return result if result else [text]
                
                # è¿‡æ»¤æ‰æ— æ•ˆçš„å¥å­ï¼ˆåªåŒ…å«æ ‡ç‚¹ç¬¦å·ã€è¡¨æƒ…ç¬¦å·ç­‰ï¼‰
                valid_sentences = []
                for sent in sentences_list:
                    if has_valid_text(sent):
                        valid_sentences.append(sent)
                    else:
                        logger.debug(f"âš ï¸ è·³è¿‡æ— æ•ˆå¥å­ï¼ˆåªåŒ…å«æ ‡ç‚¹/è¡¨æƒ…ï¼‰: {sent[:50]}...")
                
                logger.info(f"ğŸ“Š è¿‡æ»¤åæœ‰æ•ˆå¥å­: {len(valid_sentences)}/{len(sentences_list)} å¥")

                # å¯¹è¿‡é•¿çš„å¥å­è¿›è¡Œè¿›ä¸€æ­¥æ‹†åˆ†ï¼ˆè…¾è®¯äº‘TTSæœ‰é•¿åº¦é™åˆ¶ï¼‰
                MAX_SENTENCE_LENGTH = 200  # è…¾è®¯äº‘TTSå®é™…é™åˆ¶å¤§çº¦200å­—ç¬¦ä»¥å†…
                final_sentences = []

                for sent in valid_sentences:
                    if len(sent) <= MAX_SENTENCE_LENGTH:
                        final_sentences.append(sent)
                        logger.debug(f"âœ… å¥å­é•¿åº¦æ­£å¸¸: {len(sent)} å­—ç¬¦")
                    else:
                        logger.warning(f"âš ï¸ å¥å­è¿‡é•¿ ({len(sent)} å­—ç¬¦)ï¼Œè¿›è¡Œè¿›ä¸€æ­¥æ‹†åˆ†: {sent[:80]}...")
                        # å¯¹é•¿å¥å­è¿›è¡Œæ™ºèƒ½æ‹†åˆ†
                        sub_sentences = split_long_sentence(sent, MAX_SENTENCE_LENGTH)
                        final_sentences.extend(sub_sentences)
                        logger.info(f"ğŸ“ é•¿å¥å­æ‹†åˆ†ä¸º {len(sub_sentences)} ä¸ªå­å¥")

                logger.info(f"ğŸ“Š æœ€ç»ˆå¥å­æ•°: {len(final_sentences)} å¥ï¼ˆåŒ…å«æ‹†åˆ†åçš„å­å¥ï¼‰")

                # æ‰“å°æœ€ç»ˆå¥å­åˆ—è¡¨
                for idx, sent in enumerate(final_sentences, 1):
                    logger.info(f"   æœ€ç»ˆå¥å­ {idx}: {sent[:60]}{'...' if len(sent) > 60 else ''}")

                sentence_count = 0
                success_count = 0
                
                # é€å¥å¤„ç†
                for idx, sentence_text in enumerate(final_sentences):
                    if not sentence_text.strip():
                        logger.warning(f"âš ï¸ è·³è¿‡ç©ºå¥å­ {idx + 1}")
                        continue
                    
                    # å†æ¬¡æ£€æŸ¥æ–‡æœ¬æœ‰æ•ˆæ€§
                    if not has_valid_text(sentence_text):
                        logger.warning(f"âš ï¸ è·³è¿‡æ— æ•ˆæ–‡æœ¬ï¼ˆæ— æœ‰æ•ˆå­—ç¬¦ï¼‰: {sentence_text[:50]}...")
                        continue
                    
                    sentence_count += 1
                    total_sentences = len(final_sentences)
                    logger.debug(f"ğŸ“ å¼€å§‹å¤„ç†ç¬¬ {sentence_count}/{total_sentences} å¥ (é•¿åº¦: {len(sentence_text)}): {sentence_text[:80]}...")
                        
                    try:
                        # è°ƒç”¨TTSæœåŠ¡è¿›è¡Œè½¬æ¢
                        logger.info(f"ğŸ¬ å¼€å§‹å¤„ç†å¥å­ {sentence_count}/{len(final_sentences)}: {sentence_text[:50]}...")
                        audio_base64 = tts_service.text_to_speech_base64(
                            text=sentence_text,
                            voice_id=voice_id,
                            speed=speed,
                            use_cache=use_cache
                        )
                        
                        if audio_base64:
                            success_count += 1
                            logger.info(f"âœ… å¥å­ {sentence_count} è½¬æ¢æˆåŠŸï¼Œå‡†å¤‡å‘é€éŸ³é¢‘æ•°æ®ï¼ˆ{len(audio_base64)} bytes base64ï¼‰")
                            # å‘é€éŸ³é¢‘æ•°æ®
                            yield f"event: audio\n"
                            yield f"data: {json.dumps({'audio': audio_base64, 'sentence': sentence_text, 'index': sentence_count, 'total': total_sentences}, ensure_ascii=False)}\n\n"
                            logger.info(f"ğŸ“¤ å¥å­ {sentence_count} éŸ³é¢‘æ•°æ®å·²å‘é€")
                        else:
                            logger.warning(f"âš ï¸ å¥å­ {sentence_count} è½¬æ¢å¤±è´¥ï¼ˆè¿”å›Noneï¼‰")
                            # å³ä½¿è½¬æ¢å¤±è´¥ï¼Œä¹Ÿå‘é€ä¸€ä¸ªé”™è¯¯äº‹ä»¶ï¼Œè®©å‰ç«¯çŸ¥é“è¿™ä¸€å¥å¤„ç†äº†
                            yield f"event: audio_error\n"
                            yield f"data: {json.dumps({'sentence': sentence_text, 'index': sentence_count, 'total': total_sentences, 'message': 'TTSè½¬æ¢å¤±è´¥'}, ensure_ascii=False)}\n\n"
                    except Exception as e:
                        logger.error(f"âŒ å¥å­ {sentence_count} å¤„ç†å¼‚å¸¸: {str(e)}", exc_info=True)
                        # å‘é€é”™è¯¯äº‹ä»¶ï¼Œä½†ç»§ç»­å¤„ç†ä¸‹ä¸€å¥
                        yield f"event: audio_error\n"
                        yield f"data: {json.dumps({'sentence': sentence_text, 'index': sentence_count, 'total': total_sentences, 'message': str(e)}, ensure_ascii=False)}\n\n"
                        logger.info(f"ğŸ”„ ç»§ç»­å¤„ç†ä¸‹ä¸€å¥...")
                                    
                
                # å®Œæˆäº‹ä»¶
                yield f"event: completed\n"
                yield f"data: {json.dumps({'message': f'TTSè½¬æ¢å®Œæˆï¼Œå…±å¤„ç† {sentence_count} å¥ï¼ŒæˆåŠŸ {success_count} å¥', 'total': sentence_count, 'success': success_count}, ensure_ascii=False)}\n\n"
                
            except Exception as e:
                logger.error(f"âŒ æµå¼TTSå¤±è´¥: {str(e)}", exc_info=True)
                yield f"event: error\n"
                yield f"data: {json.dumps({'message': str(e)}, ensure_ascii=False)}\n\n"
        
        return Response(
            stream_with_context(generate()),
            content_type='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'X-Accel-Buffering': 'no'
            }
        )
            
    except Exception as e:
        logger.error(f"âŒ æµå¼TTSåˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return jsonify({
            'code': 500,
            'data': {},
            'success': False,
            'message': str(e)
        }), 500


@tts_bp.route('/tts/synthesize', methods=['POST'], endpoint='text_to_speech')
@token_required
def text_to_speech(user_id):
    """
    æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆä¸€æ¬¡æ€§è¿”å›ï¼‰
    
    Headers:
        Authorization: Bearer <token>
    
    Body:
        {
            "text": "è¦è½¬æ¢çš„æ–‡æœ¬",
            "voice_id": "7426720361753903141",
            "speed": 1.0,
            "use_cache": true
        }
    
    Returns:
        JSON: {
            "success": true,
            "audio_base64": "base64ç¼–ç çš„éŸ³é¢‘æ•°æ®"
        }
    """
    try:
        data = request.get_json()
        
        text = data.get('text')
        if not text:
            return jsonify({
                'code': 400,
                'data': {},
                'success': False,
                'message': 'æ–‡æœ¬ä¸èƒ½ä¸ºç©º'
            }), 400
        
        voice_id = data.get('voice_id', '7426720361753903141')
        speed = float(data.get('speed', 1.0))
        use_cache = data.get('use_cache', True)
        
        # è°ƒç”¨TTSæœåŠ¡
        audio_base64 = tts_service.text_to_speech_base64(
            text=text,
            voice_id=voice_id,
            speed=speed,
            use_cache=use_cache
        )
        
        if audio_base64:
            return jsonify({
                'code': 200,
                'data': {
                    'audio_base64': audio_base64,
                    'text': text
                },
                'success': True
            }), 200
        else:
            return jsonify({
                'code': 500,
                'data': {},
                'success': False,
                'message': 'TTSè½¬æ¢å¤±è´¥'
            }), 500
            
    except Exception as e:
        logger.error(f"âŒ TTSè½¬æ¢å¤±è´¥: {str(e)}")
        return jsonify({
            'code': 500,
            'data': {},
            'success': False,
            'message': str(e)
        }), 500


@tts_bp.route('/tts/batch', methods=['POST'], endpoint='batch_text_to_speech')
@token_required
def batch_text_to_speech(user_id):
    """
    æ‰¹é‡æ–‡æœ¬è½¬è¯­éŸ³
    
    Headers:
        Authorization: Bearer <token>
    
    Body:
        {
            "texts": ["æ–‡æœ¬1", "æ–‡æœ¬2", ...],
            "voice_id": "7426720361753903141"
        }
    
    Returns:
        JSON: {
            "success": true,
            "results": [
                {"text": "...", "audio_base64": "...", "success": true},
                ...
            ]
        }
    """
    try:
        data = request.get_json()
        
        texts = data.get('texts', [])
        if not texts or not isinstance(texts, list):
            return jsonify({
                'code': 400,
                'data': {},
                'success': False,
                'message': 'æ–‡æœ¬åˆ—è¡¨æ— æ•ˆ'
            }), 400
        
        voice_id = data.get('voice_id', '7426720361753903141')
        speed = float(data.get('speed', 1.0))

        # æ‰¹é‡è½¬æ¢
        results = tts_service.batch_text_to_speech(texts, voice_id, speed)
        
        return jsonify({
            'code': 200,
            'data': {
                'total': len(results),
                'results': results
            },
            'success': True
        }), 200
        
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡TTSå¤±è´¥: {str(e)}")
        return jsonify({
            'code': 500,
            'data': {},
            'success': False,
            'message': str(e)
        }), 500


@tts_bp.route('/tts/pregenerate-onboarding', methods=['POST'], endpoint='pregenerate_onboarding_audios')
@token_required
def pregenerate_onboarding_audios(user_id):
    """
    é¢„ç”Ÿæˆæ–°æ‰‹å¼•å¯¼çš„æ‰€æœ‰è¯­éŸ³
    
    Headers:
        Authorization: Bearer <token>
    
    Returns:
        JSON: {
            "success": true,
            "audios": {
                "1": "base64éŸ³é¢‘1",
                "2": "base64éŸ³é¢‘2",
                ...
            }
        }
    """
    try:
        results = tts_service.pregenerate_onboarding_audios()
        
        return jsonify({
            'code': 200,
            'data': {
                'total_steps': len(results),
                'audios': results
            },
            'success': True
        }), 200
        
    except Exception as e:
        logger.error(f"âŒ é¢„ç”Ÿæˆå¼•å¯¼è¯­éŸ³å¤±è´¥: {str(e)}")
        return jsonify({
            'code': 500,
            'data': {},
            'success': False,
            'message': str(e)
        }), 500


@tts_bp.route('/tts/cache/stats', methods=['GET'], endpoint='get_cache_stats')
@token_required
def get_cache_stats(user_id):
    """
    è·å–TTSç¼“å­˜ç»Ÿè®¡
    
    Headers:
        Authorization: Bearer <token>
    
    Returns:
        JSON: ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        stats = tts_service.get_cache_stats()
        return jsonify({
            'code': 200,
            'data': {'stats': stats},
            'success': True
        }), 200
        
    except Exception as e:
        logger.error(f"âŒ è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {str(e)}")
        return jsonify({
            'code': 500,
            'data': {},
            'success': False,
            'message': str(e)
        }), 500


@tts_bp.route('/tts/cache/clear', methods=['POST'], endpoint='clear_cache')
@token_required
def clear_cache(user_id):
    """
    æ¸…ç†TTSç¼“å­˜

    Headers:
        Authorization: Bearer <token>

    Body:
        {
            "older_than_days": 30
        }

    Returns:
        JSON: æ¸…ç†ç»“æœ
    """
    try:
        data = request.get_json() or {}
        older_than_days = data.get('older_than_days', 30)

        # æ¸…ç†æ–‡ä»¶ç³»ç»Ÿç¼“å­˜
        file_count = tts_service.clear_cache(older_than_days)

        # æ¸…ç†æ•°æ®åº“è®°å½•
        try:
            from models.tts_cache import TTSCache
            db_count = TTSCache.cleanup_expired(older_than_days)
        except Exception as db_e:
            logger.warning(f"âš ï¸ æ¸…ç†æ•°æ®åº“ç¼“å­˜è®°å½•å¤±è´¥: {str(db_e)}")
            db_count = 0

        return jsonify({
            'code': 200,
            'data': {
                'cleared_files': file_count,
                'cleared_db_records': db_count,
                'message': f'å·²æ¸…ç† {file_count} ä¸ªç¼“å­˜æ–‡ä»¶å’Œ {db_count} æ¡æ•°æ®åº“è®°å½•'
            },
            'success': True
        }), 200

    except Exception as e:
        logger.error(f"âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {str(e)}")
        return jsonify({
            'code': 500,
            'data': {},
            'success': False,
            'message': str(e)
        }), 500


@tts_bp.route('/tts/cache/search', methods=['GET'], endpoint='search_cache')
@token_required
def search_cache(user_id):
    """
    æœç´¢TTSç¼“å­˜è®°å½•

    Headers:
        Authorization: Bearer <token>

    Query Parameters:
        text: æœç´¢æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
        voice_id: è¯­éŸ³IDï¼ˆå¯é€‰ï¼‰
        speed: è¯­é€Ÿï¼ˆå¯é€‰ï¼‰
        limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶ï¼ˆé»˜è®¤10ï¼‰

    Returns:
        JSON: ç¼“å­˜è®°å½•åˆ—è¡¨
    """
    try:
        from models.tts_cache import TTSCache

        text = request.args.get('text')
        voice_id = request.args.get('voice_id')
        speed_str = request.args.get('speed')
        limit = int(request.args.get('limit', 10))

        speed = float(speed_str) if speed_str else None

        results = []

        if text:
            # æœç´¢ç›¸ä¼¼æ–‡æœ¬
            cache_records = TTSCache.search_similar_text(text, limit)
            results = [record.to_dict() for record in cache_records]
        else:
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            conditions = []
            params = []

            if voice_id:
                conditions.append("voice_id = %s")
                params.append(voice_id)

            if speed is not None:
                conditions.append("speed = %s")
                params.append(speed)

            if conditions:
                sql = f"""
                    SELECT * FROM tts_cache
                    WHERE {' AND '.join(conditions)} AND is_active = TRUE
                    ORDER BY last_accessed DESC
                    LIMIT %s
                """
                params.append(limit)

                from utils.database import execute_query
                rows = execute_query(sql, tuple(params))
                results = [TTSCache(**row).to_dict() for row in rows]
            else:
                # è·å–æœ€è¿‘çš„ç¼“å­˜è®°å½•
                sql = """
                    SELECT * FROM tts_cache
                    WHERE is_active = TRUE
                    ORDER BY last_accessed DESC
                    LIMIT %s
                """
                from utils.database import execute_query
                rows = execute_query(sql, (limit,))
                results = [TTSCache(**row).to_dict() for row in rows]

        return jsonify({
            'code': 200,
            'data': {
                'total': len(results),
                'results': results
            },
            'success': True
        }), 200

    except Exception as e:
        logger.error(f"âŒ æœç´¢ç¼“å­˜å¤±è´¥: {str(e)}")
        return jsonify({
            'code': 500,
            'data': {},
            'success': False,
            'message': str(e)
        }), 500


@tts_bp.route('/tts/cache/db-stats', methods=['GET'], endpoint='get_db_cache_stats')
@token_required
def get_db_cache_stats(user_id):
    """
    è·å–æ•°æ®åº“ç¼“å­˜ç»Ÿè®¡

    Headers:
        Authorization: Bearer <token>

    Returns:
        JSON: æ•°æ®åº“ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        from models.tts_cache import TTSCache

        db_stats = TTSCache.get_cache_stats()

        return jsonify({
            'code': 200,
            'data': {'db_stats': db_stats},
            'success': True
        }), 200

    except Exception as e:
        logger.error(f"âŒ è·å–æ•°æ®åº“ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {str(e)}")
        return jsonify({
            'code': 500,
            'data': {},
            'success': False,
            'message': str(e)
        }), 500

